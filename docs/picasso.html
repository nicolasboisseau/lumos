<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>lumos.picasso API documentation</title>
<meta name="description" content="Main functions to generate cell-painted platemaps with Lumos Picasso." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>lumos.picasso</code></h1>
</header>
<section id="section-intro">
<p>Main functions to generate cell-painted platemaps with Lumos Picasso.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#!/usr/bin/env python
# -*- coding: utf-8 -*-

&#39;&#39;&#39;
Main functions to generate cell-painted platemaps with Lumos Picasso.
&#39;&#39;&#39;

import sys
import os
import math
import random
import shutil
from pathlib import Path

import cv2
from tqdm import tqdm
import numpy as np
import pandas as pd

from . import logger
from . import toolbox
from . import parameters


def create_temp_and_output_folders(temp_path, output_path, scope, plate_name, style):
    &#39;&#39;&#39;
    Creates a directory structure depending on the scope. This is where the multiplexed well images will be stored.
    If the scope is &#39;plate&#39;, this will be a temporary directory for them to be stored before concatenation.
    If the scope is &#39;wells&#39; or &#39;sites&#39;, this will be their output folder.

            Parameters:
                    temp_path (Path): The path to the folder where temporary data can be stored.
                    output_path (Path): The path to the folder where the output images should be stored.
                    scope (string): &#39;plate&#39;,&#39;wells&#39; or &#39;sites&#39; (this will have an impact on the resizing of the well/site images).
                    plate_name (string): Name of the current plate.
                    style (string): The name of the style being used to generate the colorized image.

            Returns:
                    Path to the root of the created folder structure.
    &#39;&#39;&#39;

    # If the scope is plate, we put the multiplexed well images into a Temp
    # folder before they are concatenated for final output.
    if scope == &#39;plate&#39;:
        # Create a Temp folder
        new_folder = temp_path + &#34;/tmpgen-&#34; + plate_name + &#34;picasso&#34;
        # Remove folder if existing
        shutil.rmtree(new_folder, ignore_errors=True)
        # Create the temporary directory structure to work on wells
        try:
            os.mkdir(new_folder)
            os.mkdir(new_folder + &#34;/wells&#34;)
        except FileExistsError:
            pass

    # If the scope is wells or sites, we output directly the multiplexed well
    # images in the output folder.
    if scope in (&#39;wells&#39;, &#39;sites&#39;):
        # Create the output folder
        new_folder = output_path + f&#34;/{scope}_{plate_name}_{style}&#34;
        try:
            os.mkdir(new_folder)
        except FileExistsError:
            pass

    return new_folder


def get_images_full_path(selected_channels, plate_input_path):
    &#39;&#39;&#39;
    Finds all the paths to all the channels&#39; images from the input folder

            Parameters:
                    selected_channels (string list): A list of all the channels IDs to be loaded.
                    plate_input_path (Path): The path to the folder where the input images are stored.

            Returns:
                    Path list: A list of all the paths to all images of each channels
    &#39;&#39;&#39;

    # Get the files from the plate folder, for the targeted channel
    images_full_path_list = []
    for channel in selected_channels:
        current_channel_images_full_path_list = list(
            Path(plate_input_path).glob(&#34;*&#34; + channel + &#34;.tif&#34;)
        )
        images_full_path_list.extend(current_channel_images_full_path_list)

    # Check that we get expected images for a 384 well image
    try:
        assert len(images_full_path_list) == 2304 * 5
    except AssertionError:
        print(
            &#34;The plate does not have the exact image count: expected &#34; +
            str(2304 * 5) + &#34;, got &#34;
            + str(len(images_full_path_list)),
        )

    return images_full_path_list


def build_robustized_plate_dataframe(images_full_path_list):
    &#39;&#39;&#39;
    Scans the input list of Paths to map it to the expected plate structure.
    Missing images or wells must be taken into account in the final render.

            Parameters:
                    images_full_path_list (Path list): A list of all the paths to all the images to be included in the render.

            Returns:
                    Pandas DataFrame:
                            A database of all the image paths to each channel, of each site, of each well.
                            Its columns are: [&#34;well&#34;, &#34;site&#34;, &#34;channel&#34;, &#34;filename&#34;, &#34;fullpath&#34;].
    &#39;&#39;&#39;

    # Get the filenames list
    images_full_path_list.sort()
    images_filename_list = [str(x.name) for x in images_full_path_list]

    # Get the well list
    image_well_list = [x.split(&#34;_&#34;)[1].split(&#34;_T&#34;)[0]
                       for x in images_filename_list]

    # Get the siteid list (sitesid from 1 to 6)
    image_site_list = [
        x.split(&#34;_T0001F&#34;)[1].split(&#34;L&#34;)[0] for x in images_filename_list
    ]
    image_site_list_int = [int(x) for x in image_site_list]

    # Get the channel id list (channel id from 1 to 5)
    image_channel_list = [x.split(&#34;.ti&#34;)[0][-2:] for x in images_filename_list]
    image_channel_list_int = [int(x) for x in image_channel_list]

    # Zip all in a data structure
    image_data_zip = zip(
        image_well_list,
        image_site_list_int,
        image_channel_list_int,
        images_filename_list,
        images_full_path_list,
    )

    # Convert the zip into dataframe
    data_df = pd.DataFrame(
        list(image_data_zip),
        columns=[&#34;well&#34;, &#34;site&#34;, &#34;channel&#34;, &#34;filename&#34;, &#34;fullpath&#34;],
    )

    # Get the theoretical well list for 384 well plate
    well_theoretical_list = [
        l + str(r).zfill(2) for l in &#34;ABCDEFGHIJKLMNOP&#34; for r in range(1, 25)
    ]
    well_channel_theoretical_list = [
        [w, s, c] for w in well_theoretical_list for s in range(1, 7) for c in range(1, 6)
    ]

    # Create the theoretical well dataframe
    theoretical_data_df = pd.DataFrame(
        well_channel_theoretical_list, columns=[&#34;well&#34;, &#34;site&#34;, &#34;channel&#34;]
    )

    # Join the real wells with the theoretical ones
    theoretical_data_df_joined = theoretical_data_df.merge(
        data_df,
        left_on=[&#34;well&#34;, &#34;site&#34;, &#34;channel&#34;],
        right_on=[&#34;well&#34;, &#34;site&#34;, &#34;channel&#34;],
        how=&#34;left&#34;,
    )

    # Log if there is a delta between theory and actual plate wells
    delta = set(well_theoretical_list) - set(image_well_list)
    logger.info(&#34;Well Delta &#34; + str(delta))

    return theoretical_data_df_joined


def colorizer(
    img_channels_fullpath,
    rescale_ratio,
    style,
    max_multiply_coef=1,
    display_fingerprint=False,
):
    &#39;&#39;&#39;
    Merges input images from different channels into one RGB image.

            Parameters:
                    img_channels_fullpath (Path list): The list of paths to the channels&#39; images (in proper order [C01,C02,C03,C04,C05]).
                    rescale_ratio (float): The ratio used to rescale the image before generation.
                    style (string): The name of the style being used to generate the colorized image.
                    max_multiply_coef (int): Max multiplication factor in case of random coefficient generation.
                    display_fingerprint (bool): Whether the coefficients used for generation should be printed on the output image.

            Returns:
                    8-bit cv2 image
    &#39;&#39;&#39;

    # For each channel image of the site:
    # Load images from path list + resize + convert to 8bit
    np_image_channels_array = []
    for current_image in img_channels_fullpath:
        # Load image
        img16 = cv2.imread(str(current_image), -1)
        try:
            assert img16.shape != (0, 0)
        except:
            # Create blank file if the image can&#39;t be loaded
            img16 = np.full(shape=(1000, 1000, 1),
                            fill_value=0, dtype=np.uint16)
            logger.warning(&#34;Missing or corrupted image &#34; + str(current_image))

        # Resize image according to rescale ratio
        img16 = cv2.resize(
            src=img16,
            dsize=None,
            fx=rescale_ratio,
            fy=rescale_ratio,
            interpolation=cv2.INTER_CUBIC,
        )

        # Convert image to 8bit
        img8 = (img16 / 256).astype(&#34;uint8&#34;)
        np_image_channels_array.append(img8)

    # Perform merging, according to the style
    if style == &#39;classic&#39;:
        # Initialize RGB channels to zeros
        red_channel = np.zeros(np_image_channels_array[0].shape)
        green_channel = np.zeros(np_image_channels_array[0].shape)
        blue_channel = np.zeros(np_image_channels_array[0].shape)

        # Get the current style&#39;s contrast coefficients
        contrast_coef = parameters.classic_style_parameters[&#39;contrast&#39;]
        # Add contrast to each layer according to coefficients
        for idx in range(5):
            contrast = contrast_coef[idx]
            alpha_c = float(131 * (contrast + 127)) / (127 * (131 - contrast))
            gamma_c = 127*(1-alpha_c)
            np_image_channels_array[idx] = cv2.addWeighted(
                np_image_channels_array[idx], alpha_c, np_image_channels_array[idx], 0, gamma_c)

        # Get the current style&#39;s intensity coefficients
        intensity_coef = parameters.classic_style_parameters[&#39;intensity&#39;]
        # Multiply the intensity of the channels using input coefs
        for idx, image in enumerate(np_image_channels_array):
            # Create a mask to check when value will overflow
            mask = (image &gt; (255 / intensity_coef[idx])
                    ) if intensity_coef[idx] != 0 else False
            # Clip the result to be in [0;255] if overflow
            np_image_channels_array[idx] = np.where(
                mask,
                255,
                image * intensity_coef[idx])

        # Combine the images according to their RGB coefficients
        for idx, tuned_channel_image in enumerate(np_image_channels_array):
            red_channel = red_channel + \
                (tuned_channel_image / 255 *
                 parameters.cellpainting_channels_info[idx][3][0])
            green_channel = green_channel + \
                (tuned_channel_image / 255 *
                 parameters.cellpainting_channels_info[idx][3][1])
            blue_channel = blue_channel + \
                (tuned_channel_image / 255 *
                 parameters.cellpainting_channels_info[idx][3][2])

        # Merge the Blue, Green and Red channels to form the final image
        merged_img = cv2.merge(
            (blue_channel, green_channel, red_channel)
        )

    else:

        # Get the current style&#39;s parameters
        intensity_coef = parameters.fingerprint_style_dict[style][0]
        channel_order = parameters.fingerprint_style_dict[style][1]
        target_rgb = parameters.fingerprint_style_dict[style][2]

        # Randomly initiate coefficients for each channel if they are missing
        if len(intensity_coef) == 0 and len(channel_order) == 0 and len(target_rgb) == 0:
            intensity_coef = [random.randint(
                1, max_multiply_coef) for _ in range(5)]
            channel_order = [0, 1, 2, 3, 4]
            random.shuffle(channel_order)
            target_rgb = [0, 1, 2]
            random.shuffle(target_rgb)

        # Multiply the intensity of the channels using input coefs
        np_image_array_adjusted = []
        # TODO: adapt for less than 5 selected channels?
        for index, current_coef_mult in enumerate(intensity_coef):
            np_image_array_adjusted.append(
                np_image_channels_array[index] * current_coef_mult)
        np_image_channels_array = np_image_array_adjusted

        # Merge 2 extra channels each on 1 rgb channel
        np_image_channels_array[target_rgb[0]] = (
            np_image_channels_array[target_rgb[0]] +
            np_image_channels_array[channel_order[3]]
        )
        np_image_channels_array[target_rgb[1]] = (
            np_image_channels_array[target_rgb[1]] +
            np_image_channels_array[channel_order[4]]
        )

        # Merge the 3 BGR channels into one color image
        merged_img = cv2.merge(
            (
                np_image_channels_array[channel_order[0]],
                np_image_channels_array[channel_order[1]],
                np_image_channels_array[channel_order[2]],
            )
        )

    # Add fingerprint id on image
    if display_fingerprint:
        text = str(intensity_coef) + str(channel_order) + str(
            target_rgb) if style != &#39;classic&#39; else str(parameters.classic_style_parameters)
        font = cv2.FONT_HERSHEY_SIMPLEX
        cv2.putText(
            merged_img,
            text,
            (math.ceil(10*rescale_ratio), math.ceil(990*rescale_ratio)),
            font,
            0.8*rescale_ratio,
            (192, 192, 192),
            math.ceil(2*rescale_ratio),
            cv2.INTER_AREA,
        )

    return merged_img


def generate_multiplexed_well_images(
    data_df,
    well_list,
    gen_image_output_folder,
    platemap_path,
    output_format,
    style,
    display_well_details,
    plate_name,
    scope
):
    &#39;&#39;&#39;
    Generates a colorized image from all 5 channels of a well, for all wells, and saves it in the temporary directory.

            Parameters:
                    data_df (Pandas DataFrame): Dataframe containing the paths to each channel, of each site, of each well.
                    well_list (string list): The list of wells to be generated
                    gen_image_output_folder (Path): The path to the folder where the images generated should be stored.
                    platemap_path (Path): The path to the platemap file of the plate.
                    output_format (string): The format/extension of the generated output images.
                    style (string): The name of the style being used to generate the colorized image.
                    display_well_details (bool): Whether or not the name of the well should be printed on its generated image.
                    plate_name (string): Name of the current plate.
                    scope (string): &#39;plate&#39;,&#39;wells&#39; or &#39;sites&#39; (this will have an impact on the resizing of the well/site images).

            Returns:
                    True (in case of success)
    &#39;&#39;&#39;

    # Define the rescale ratio based on the scope
    if scope == &#39;wells&#39;:
        rescale_ratio = parameters.rescale_ratio_picasso_wells
    elif scope == &#39;plate&#39;:
        rescale_ratio = parameters.rescale_ratio_picasso_plate
    else:
        rescale_ratio = 1

    # Multiplex all well/site channels into 1 well/site 8bit colored image
    wellprogressbar = tqdm(well_list, unit=&#34;wells&#34;, leave=False)
    for current_well in wellprogressbar:
        # For each well, generate the multiplexed images of its 6 sites
        current_well_sites_multiplexed_image_list = []
        for current_site in range(1, 7):

            # Get the image path list for the channels of the site, in the correct order
            current_sites_df = data_df[
                ((data_df[&#34;well&#34;] == current_well) &amp;
                 (data_df[&#34;site&#34;] == current_site))
            ]
            current_sites_df_ordered = current_sites_df.sort_values(
                by=&#34;channel&#34;, ascending=True
            )
            channel_images_path = \
                current_sites_df_ordered[&#34;fullpath&#34;].to_list()

            # Generate the multiplexed image of the current site
            multiplexed_site_image = colorizer(
                img_channels_fullpath=channel_images_path,
                rescale_ratio=rescale_ratio,
                max_multiply_coef=8,
                style=style,
            )

            if scope == &#39;sites&#39;:
                # Return the site image directly
                cv2.imwrite(
                    gen_image_output_folder +
                    f&#34;/{current_well}_s{current_site}.{output_format}&#34;,
                    multiplexed_site_image,
                )

            else:
                # Collect images in memory for site image concatenation
                # into one well image
                current_well_sites_multiplexed_image_list.append(
                    multiplexed_site_image)

        if scope in (&#39;plate&#39;, &#39;wells&#39;):
            # Concatenate the site images into one well image
            sites_row1 = cv2.hconcat(
                current_well_sites_multiplexed_image_list[:3]
            )
            sites_row2 = cv2.hconcat(
                current_well_sites_multiplexed_image_list[3:]
            )
            current_well_image = cv2.vconcat([sites_row1, sites_row2])

            # Add fingerprint on image
            if display_well_details:

                # Compose well label
                text = current_well
                if platemap_path is not None:
                    # If the platemap is provided, extract all required columns
                    pm_well_column = parameters.platemap_columns[&#39;well_column_name&#39;]
                    pm_id_column = parameters.platemap_columns[&#39;id_column_name&#39;]

                    platemap_df = pd.read_csv(platemap_path,
                                              sep=&#39;\t&#39;,
                                              header=0,
                                              usecols=[pm_well_column, pm_id_column])

                    # Select the row of the current well (if there is one)
                    current_platemap_row = platemap_df.loc[platemap_df[pm_well_column]
                                                           == current_well]

                    # If there is indeed a row, add the JCP to the well label
                    if len(current_platemap_row.index) != 0:
                        current_compound = current_platemap_row.iloc[0][pm_id_column]
                        text = current_well + &#34; - &#34; + current_compound

                # Add the label to the well image
                font = cv2.FONT_HERSHEY_SIMPLEX
                cv2.putText(
                    img=current_well_image,
                    text=text,
                    org=(math.ceil(80*rescale_ratio),
                         math.ceil(80*rescale_ratio)),
                    fontFace=font,
                    fontScale=2.2*rescale_ratio,
                    thickness=math.ceil(3*rescale_ratio),
                    color=(192, 192, 192),
                    lineType=cv2.INTER_AREA,
                )

            # Output the well images in the pre-defined temp/output folder
            # depending on the scope
            if scope == &#39;plate&#39;:
                # Add well borders
                image_shape = current_well_image.shape
                cv2.rectangle(
                    current_well_image,
                    (0, 0),
                    (image_shape[1], image_shape[0]),
                    (192, 192, 192),
                    math.ceil(8*rescale_ratio),
                )
                # Return the image
                cv2.imwrite(
                    gen_image_output_folder +
                    f&#34;/wells/well-{current_well}.{output_format}&#34;,
                    current_well_image,
                )
            elif scope == &#39;wells&#39;:
                # Return the image
                cv2.imwrite(
                    gen_image_output_folder +
                    f&#34;/{plate_name}_{current_well}_{style}.{output_format}&#34;,
                    current_well_image,
                )


def concatenate_well_images(well_list, temp_folder_path, output_format):
    &#39;&#39;&#39;
    Loads all temporary well images from the temporary directory and concatenates them into one image of the whole plate.

            Parameters:
                    well_list (string list): A list of all the well IDs (e.g. [&#39;A01&#39;, &#39;A02&#39;, &#39;A03&#39;, ...]).
                    temp_folder_path (Path): The path to the folder where temporary data can be stored.

            Returns:
                    8-bit cv2 image: The concatenated image of all the wells
    &#39;&#39;&#39;

    # Load all well images and store images in memory into a list
    print(&#34;Load well images in memory..&#34;)
    logger.info(&#34;Load well images in memory..&#34;)

    image_well_data = []
    for current_well in well_list:
        well_image = toolbox.load_well_image(
            current_well,
            temp_folder_path + &#34;/wells&#34;,
            image_format=output_format,
        )
        image_well_data.append(well_image)

    # Concatenate all the well images into horizontal stripes (1 per row)
    logger.info(&#34;Concatenate images into a plate..&#34;)

    image_row_data = []
    for current_plate_row in range(1, 17):
        # Concatenate horizontally and vertically
        well_start_id = ((current_plate_row - 1) * 24) + 0
        well_end_id = current_plate_row * 24
        sites_row = cv2.hconcat(image_well_data[well_start_id:well_end_id])
        image_row_data.append(sites_row)

    # Concatenate all the stripes into 1 image
    plate_image = cv2.vconcat(image_row_data)

    return plate_image


def picasso_generate_plate_image(
    source_path,
    plate_name,
    output_path,
    temp_folder_path,
    platemap_path,
    output_format,
    style,
    scope,
    single_well,
    display_well_details,
):
    &#39;&#39;&#39;
    Generates cell-painted colorized images of individual wells or of a whole plate.

            Parameters:
                    source_path (Path): The folder where the input images of the plate are stored.
                    plate_name (string): The name of the plate being rendered.
                    output_path (Path): The path to the folder where the output images should be stored.
                    temp_folder_path (Path): The path to the folder where temporary data can be stored.
                    platemap_path (Path): The path to the platemap file of the plate.
                    output_format (string): The format/extension of the generated output images.
                    style (string): The name of the rendering style.
                    scope (string):
                            Either &#39;wells&#39; or &#39;plate&#39;. Defines if we should generate individual well images,
                            or concatenate them into a single plate image.
                    single_well (string): If not None, name of a unique well to render the image for.
                    display_well_details (bool): Whether or not the name of the well should be written on the generated images.

            Returns:
                    8 bit cv2 image(s):
                            If the scope is &#39;wells&#39;, then all colorized well images are outputed to the output folder.
                            If the scope is &#39;plate&#39;, then the well images are concatenated into one image of the whole
                            plate before being outputed to the output folder.
    &#39;&#39;&#39;

    created_folder = create_temp_and_output_folders(
        temp_folder_path, output_path, scope, plate_name, style)

    # Get the list of all paths for each channel image
    images_full_path_list = get_images_full_path(
        selected_channels=[&#34;C01&#34;, &#34;C02&#34;, &#34;C03&#34;, &#34;C04&#34;, &#34;C05&#34;],
        plate_input_path=source_path,
    )

    # Build a database of the theorical plate
    # TODO: adapt for less than 5 selected channels?
    data_df = build_robustized_plate_dataframe(images_full_path_list)

    # Get the list of wells to be rendered
    well_list = sorted(data_df[&#34;well&#34;].unique())

    # Handle the single-well request
    if single_well and single_well not in well_list:
        logger.error(&#34;Single-well parameter not a valid well&#34;)
        print(os.linesep, &#34;ERROR:&#34;, single_well,
              &#34;is not a valid well.&#34;, os.linesep)
        sys.exit()
    elif single_well:
        # Override the list of wells to be rendered
        # with the single well
        well_list = [single_well]

    # Generate the Cell-painted well images
    generate_multiplexed_well_images(
        data_df=data_df,
        well_list=well_list,
        gen_image_output_folder=created_folder,
        platemap_path=platemap_path,
        output_format=output_format,
        style=style,
        display_well_details=display_well_details,
        plate_name=plate_name,
        scope=scope,
    )

    if scope in (&#39;sites&#39;, &#39;wells&#39;):
        print(f&#34; -&gt; Saved {scope} images in {output_path}&#34;)
    elif scope == &#39;plate&#39;:
        # Concatenate well images into a plate image
        plate_image = concatenate_well_images(
            well_list, created_folder, output_format)

        # Save the concatenated image in the output folder
        plate_image_path = (
            output_path + f&#34;/{plate_name}-picasso-{style}.{output_format}&#34;
        )
        cv2.imwrite(plate_image_path, plate_image)

        print(&#34; -&gt; Generated image of size:&#34;, plate_image.shape)
        print(&#34; -&gt; Saved as &#34;, plate_image_path)

        # Purge the temp files
        logger.info(&#34;Purge temporary folder&#34;)
        shutil.rmtree(created_folder, ignore_errors=True)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="lumos.picasso.build_robustized_plate_dataframe"><code class="name flex">
<span>def <span class="ident">build_robustized_plate_dataframe</span></span>(<span>images_full_path_list)</span>
</code></dt>
<dd>
<div class="desc"><p>Scans the input list of Paths to map it to the expected plate structure.
Missing images or wells must be taken into account in the final render.</p>
<pre><code>    Parameters:
            images_full_path_list (Path list): A list of all the paths to all the images to be included in the render.

    Returns:
            Pandas DataFrame:
                    A database of all the image paths to each channel, of each site, of each well.
                    Its columns are: ["well", "site", "channel", "filename", "fullpath"].
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build_robustized_plate_dataframe(images_full_path_list):
    &#39;&#39;&#39;
    Scans the input list of Paths to map it to the expected plate structure.
    Missing images or wells must be taken into account in the final render.

            Parameters:
                    images_full_path_list (Path list): A list of all the paths to all the images to be included in the render.

            Returns:
                    Pandas DataFrame:
                            A database of all the image paths to each channel, of each site, of each well.
                            Its columns are: [&#34;well&#34;, &#34;site&#34;, &#34;channel&#34;, &#34;filename&#34;, &#34;fullpath&#34;].
    &#39;&#39;&#39;

    # Get the filenames list
    images_full_path_list.sort()
    images_filename_list = [str(x.name) for x in images_full_path_list]

    # Get the well list
    image_well_list = [x.split(&#34;_&#34;)[1].split(&#34;_T&#34;)[0]
                       for x in images_filename_list]

    # Get the siteid list (sitesid from 1 to 6)
    image_site_list = [
        x.split(&#34;_T0001F&#34;)[1].split(&#34;L&#34;)[0] for x in images_filename_list
    ]
    image_site_list_int = [int(x) for x in image_site_list]

    # Get the channel id list (channel id from 1 to 5)
    image_channel_list = [x.split(&#34;.ti&#34;)[0][-2:] for x in images_filename_list]
    image_channel_list_int = [int(x) for x in image_channel_list]

    # Zip all in a data structure
    image_data_zip = zip(
        image_well_list,
        image_site_list_int,
        image_channel_list_int,
        images_filename_list,
        images_full_path_list,
    )

    # Convert the zip into dataframe
    data_df = pd.DataFrame(
        list(image_data_zip),
        columns=[&#34;well&#34;, &#34;site&#34;, &#34;channel&#34;, &#34;filename&#34;, &#34;fullpath&#34;],
    )

    # Get the theoretical well list for 384 well plate
    well_theoretical_list = [
        l + str(r).zfill(2) for l in &#34;ABCDEFGHIJKLMNOP&#34; for r in range(1, 25)
    ]
    well_channel_theoretical_list = [
        [w, s, c] for w in well_theoretical_list for s in range(1, 7) for c in range(1, 6)
    ]

    # Create the theoretical well dataframe
    theoretical_data_df = pd.DataFrame(
        well_channel_theoretical_list, columns=[&#34;well&#34;, &#34;site&#34;, &#34;channel&#34;]
    )

    # Join the real wells with the theoretical ones
    theoretical_data_df_joined = theoretical_data_df.merge(
        data_df,
        left_on=[&#34;well&#34;, &#34;site&#34;, &#34;channel&#34;],
        right_on=[&#34;well&#34;, &#34;site&#34;, &#34;channel&#34;],
        how=&#34;left&#34;,
    )

    # Log if there is a delta between theory and actual plate wells
    delta = set(well_theoretical_list) - set(image_well_list)
    logger.info(&#34;Well Delta &#34; + str(delta))

    return theoretical_data_df_joined</code></pre>
</details>
</dd>
<dt id="lumos.picasso.colorizer"><code class="name flex">
<span>def <span class="ident">colorizer</span></span>(<span>img_channels_fullpath, rescale_ratio, style, max_multiply_coef=1, display_fingerprint=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Merges input images from different channels into one RGB image.</p>
<pre><code>    Parameters:
            img_channels_fullpath (Path list): The list of paths to the channels' images (in proper order [C01,C02,C03,C04,C05]).
            rescale_ratio (float): The ratio used to rescale the image before generation.
            style (string): The name of the style being used to generate the colorized image.
            max_multiply_coef (int): Max multiplication factor in case of random coefficient generation.
            display_fingerprint (bool): Whether the coefficients used for generation should be printed on the output image.

    Returns:
            8-bit cv2 image
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def colorizer(
    img_channels_fullpath,
    rescale_ratio,
    style,
    max_multiply_coef=1,
    display_fingerprint=False,
):
    &#39;&#39;&#39;
    Merges input images from different channels into one RGB image.

            Parameters:
                    img_channels_fullpath (Path list): The list of paths to the channels&#39; images (in proper order [C01,C02,C03,C04,C05]).
                    rescale_ratio (float): The ratio used to rescale the image before generation.
                    style (string): The name of the style being used to generate the colorized image.
                    max_multiply_coef (int): Max multiplication factor in case of random coefficient generation.
                    display_fingerprint (bool): Whether the coefficients used for generation should be printed on the output image.

            Returns:
                    8-bit cv2 image
    &#39;&#39;&#39;

    # For each channel image of the site:
    # Load images from path list + resize + convert to 8bit
    np_image_channels_array = []
    for current_image in img_channels_fullpath:
        # Load image
        img16 = cv2.imread(str(current_image), -1)
        try:
            assert img16.shape != (0, 0)
        except:
            # Create blank file if the image can&#39;t be loaded
            img16 = np.full(shape=(1000, 1000, 1),
                            fill_value=0, dtype=np.uint16)
            logger.warning(&#34;Missing or corrupted image &#34; + str(current_image))

        # Resize image according to rescale ratio
        img16 = cv2.resize(
            src=img16,
            dsize=None,
            fx=rescale_ratio,
            fy=rescale_ratio,
            interpolation=cv2.INTER_CUBIC,
        )

        # Convert image to 8bit
        img8 = (img16 / 256).astype(&#34;uint8&#34;)
        np_image_channels_array.append(img8)

    # Perform merging, according to the style
    if style == &#39;classic&#39;:
        # Initialize RGB channels to zeros
        red_channel = np.zeros(np_image_channels_array[0].shape)
        green_channel = np.zeros(np_image_channels_array[0].shape)
        blue_channel = np.zeros(np_image_channels_array[0].shape)

        # Get the current style&#39;s contrast coefficients
        contrast_coef = parameters.classic_style_parameters[&#39;contrast&#39;]
        # Add contrast to each layer according to coefficients
        for idx in range(5):
            contrast = contrast_coef[idx]
            alpha_c = float(131 * (contrast + 127)) / (127 * (131 - contrast))
            gamma_c = 127*(1-alpha_c)
            np_image_channels_array[idx] = cv2.addWeighted(
                np_image_channels_array[idx], alpha_c, np_image_channels_array[idx], 0, gamma_c)

        # Get the current style&#39;s intensity coefficients
        intensity_coef = parameters.classic_style_parameters[&#39;intensity&#39;]
        # Multiply the intensity of the channels using input coefs
        for idx, image in enumerate(np_image_channels_array):
            # Create a mask to check when value will overflow
            mask = (image &gt; (255 / intensity_coef[idx])
                    ) if intensity_coef[idx] != 0 else False
            # Clip the result to be in [0;255] if overflow
            np_image_channels_array[idx] = np.where(
                mask,
                255,
                image * intensity_coef[idx])

        # Combine the images according to their RGB coefficients
        for idx, tuned_channel_image in enumerate(np_image_channels_array):
            red_channel = red_channel + \
                (tuned_channel_image / 255 *
                 parameters.cellpainting_channels_info[idx][3][0])
            green_channel = green_channel + \
                (tuned_channel_image / 255 *
                 parameters.cellpainting_channels_info[idx][3][1])
            blue_channel = blue_channel + \
                (tuned_channel_image / 255 *
                 parameters.cellpainting_channels_info[idx][3][2])

        # Merge the Blue, Green and Red channels to form the final image
        merged_img = cv2.merge(
            (blue_channel, green_channel, red_channel)
        )

    else:

        # Get the current style&#39;s parameters
        intensity_coef = parameters.fingerprint_style_dict[style][0]
        channel_order = parameters.fingerprint_style_dict[style][1]
        target_rgb = parameters.fingerprint_style_dict[style][2]

        # Randomly initiate coefficients for each channel if they are missing
        if len(intensity_coef) == 0 and len(channel_order) == 0 and len(target_rgb) == 0:
            intensity_coef = [random.randint(
                1, max_multiply_coef) for _ in range(5)]
            channel_order = [0, 1, 2, 3, 4]
            random.shuffle(channel_order)
            target_rgb = [0, 1, 2]
            random.shuffle(target_rgb)

        # Multiply the intensity of the channels using input coefs
        np_image_array_adjusted = []
        # TODO: adapt for less than 5 selected channels?
        for index, current_coef_mult in enumerate(intensity_coef):
            np_image_array_adjusted.append(
                np_image_channels_array[index] * current_coef_mult)
        np_image_channels_array = np_image_array_adjusted

        # Merge 2 extra channels each on 1 rgb channel
        np_image_channels_array[target_rgb[0]] = (
            np_image_channels_array[target_rgb[0]] +
            np_image_channels_array[channel_order[3]]
        )
        np_image_channels_array[target_rgb[1]] = (
            np_image_channels_array[target_rgb[1]] +
            np_image_channels_array[channel_order[4]]
        )

        # Merge the 3 BGR channels into one color image
        merged_img = cv2.merge(
            (
                np_image_channels_array[channel_order[0]],
                np_image_channels_array[channel_order[1]],
                np_image_channels_array[channel_order[2]],
            )
        )

    # Add fingerprint id on image
    if display_fingerprint:
        text = str(intensity_coef) + str(channel_order) + str(
            target_rgb) if style != &#39;classic&#39; else str(parameters.classic_style_parameters)
        font = cv2.FONT_HERSHEY_SIMPLEX
        cv2.putText(
            merged_img,
            text,
            (math.ceil(10*rescale_ratio), math.ceil(990*rescale_ratio)),
            font,
            0.8*rescale_ratio,
            (192, 192, 192),
            math.ceil(2*rescale_ratio),
            cv2.INTER_AREA,
        )

    return merged_img</code></pre>
</details>
</dd>
<dt id="lumos.picasso.concatenate_well_images"><code class="name flex">
<span>def <span class="ident">concatenate_well_images</span></span>(<span>well_list, temp_folder_path, output_format)</span>
</code></dt>
<dd>
<div class="desc"><p>Loads all temporary well images from the temporary directory and concatenates them into one image of the whole plate.</p>
<pre><code>    Parameters:
            well_list (string list): A list of all the well IDs (e.g. ['A01', 'A02', 'A03', ...]).
            temp_folder_path (Path): The path to the folder where temporary data can be stored.

    Returns:
            8-bit cv2 image: The concatenated image of all the wells
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def concatenate_well_images(well_list, temp_folder_path, output_format):
    &#39;&#39;&#39;
    Loads all temporary well images from the temporary directory and concatenates them into one image of the whole plate.

            Parameters:
                    well_list (string list): A list of all the well IDs (e.g. [&#39;A01&#39;, &#39;A02&#39;, &#39;A03&#39;, ...]).
                    temp_folder_path (Path): The path to the folder where temporary data can be stored.

            Returns:
                    8-bit cv2 image: The concatenated image of all the wells
    &#39;&#39;&#39;

    # Load all well images and store images in memory into a list
    print(&#34;Load well images in memory..&#34;)
    logger.info(&#34;Load well images in memory..&#34;)

    image_well_data = []
    for current_well in well_list:
        well_image = toolbox.load_well_image(
            current_well,
            temp_folder_path + &#34;/wells&#34;,
            image_format=output_format,
        )
        image_well_data.append(well_image)

    # Concatenate all the well images into horizontal stripes (1 per row)
    logger.info(&#34;Concatenate images into a plate..&#34;)

    image_row_data = []
    for current_plate_row in range(1, 17):
        # Concatenate horizontally and vertically
        well_start_id = ((current_plate_row - 1) * 24) + 0
        well_end_id = current_plate_row * 24
        sites_row = cv2.hconcat(image_well_data[well_start_id:well_end_id])
        image_row_data.append(sites_row)

    # Concatenate all the stripes into 1 image
    plate_image = cv2.vconcat(image_row_data)

    return plate_image</code></pre>
</details>
</dd>
<dt id="lumos.picasso.create_temp_and_output_folders"><code class="name flex">
<span>def <span class="ident">create_temp_and_output_folders</span></span>(<span>temp_path, output_path, scope, plate_name, style)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates a directory structure depending on the scope. This is where the multiplexed well images will be stored.
If the scope is 'plate', this will be a temporary directory for them to be stored before concatenation.
If the scope is 'wells' or 'sites', this will be their output folder.</p>
<pre><code>    Parameters:
            temp_path (Path): The path to the folder where temporary data can be stored.
            output_path (Path): The path to the folder where the output images should be stored.
            scope (string): 'plate','wells' or 'sites' (this will have an impact on the resizing of the well/site images).
            plate_name (string): Name of the current plate.
            style (string): The name of the style being used to generate the colorized image.

    Returns:
            Path to the root of the created folder structure.
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_temp_and_output_folders(temp_path, output_path, scope, plate_name, style):
    &#39;&#39;&#39;
    Creates a directory structure depending on the scope. This is where the multiplexed well images will be stored.
    If the scope is &#39;plate&#39;, this will be a temporary directory for them to be stored before concatenation.
    If the scope is &#39;wells&#39; or &#39;sites&#39;, this will be their output folder.

            Parameters:
                    temp_path (Path): The path to the folder where temporary data can be stored.
                    output_path (Path): The path to the folder where the output images should be stored.
                    scope (string): &#39;plate&#39;,&#39;wells&#39; or &#39;sites&#39; (this will have an impact on the resizing of the well/site images).
                    plate_name (string): Name of the current plate.
                    style (string): The name of the style being used to generate the colorized image.

            Returns:
                    Path to the root of the created folder structure.
    &#39;&#39;&#39;

    # If the scope is plate, we put the multiplexed well images into a Temp
    # folder before they are concatenated for final output.
    if scope == &#39;plate&#39;:
        # Create a Temp folder
        new_folder = temp_path + &#34;/tmpgen-&#34; + plate_name + &#34;picasso&#34;
        # Remove folder if existing
        shutil.rmtree(new_folder, ignore_errors=True)
        # Create the temporary directory structure to work on wells
        try:
            os.mkdir(new_folder)
            os.mkdir(new_folder + &#34;/wells&#34;)
        except FileExistsError:
            pass

    # If the scope is wells or sites, we output directly the multiplexed well
    # images in the output folder.
    if scope in (&#39;wells&#39;, &#39;sites&#39;):
        # Create the output folder
        new_folder = output_path + f&#34;/{scope}_{plate_name}_{style}&#34;
        try:
            os.mkdir(new_folder)
        except FileExistsError:
            pass

    return new_folder</code></pre>
</details>
</dd>
<dt id="lumos.picasso.generate_multiplexed_well_images"><code class="name flex">
<span>def <span class="ident">generate_multiplexed_well_images</span></span>(<span>data_df, well_list, gen_image_output_folder, platemap_path, output_format, style, display_well_details, plate_name, scope)</span>
</code></dt>
<dd>
<div class="desc"><p>Generates a colorized image from all 5 channels of a well, for all wells, and saves it in the temporary directory.</p>
<pre><code>    Parameters:
            data_df (Pandas DataFrame): Dataframe containing the paths to each channel, of each site, of each well.
            well_list (string list): The list of wells to be generated
            gen_image_output_folder (Path): The path to the folder where the images generated should be stored.
            platemap_path (Path): The path to the platemap file of the plate.
            output_format (string): The format/extension of the generated output images.
            style (string): The name of the style being used to generate the colorized image.
            display_well_details (bool): Whether or not the name of the well should be printed on its generated image.
            plate_name (string): Name of the current plate.
            scope (string): 'plate','wells' or 'sites' (this will have an impact on the resizing of the well/site images).

    Returns:
            True (in case of success)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_multiplexed_well_images(
    data_df,
    well_list,
    gen_image_output_folder,
    platemap_path,
    output_format,
    style,
    display_well_details,
    plate_name,
    scope
):
    &#39;&#39;&#39;
    Generates a colorized image from all 5 channels of a well, for all wells, and saves it in the temporary directory.

            Parameters:
                    data_df (Pandas DataFrame): Dataframe containing the paths to each channel, of each site, of each well.
                    well_list (string list): The list of wells to be generated
                    gen_image_output_folder (Path): The path to the folder where the images generated should be stored.
                    platemap_path (Path): The path to the platemap file of the plate.
                    output_format (string): The format/extension of the generated output images.
                    style (string): The name of the style being used to generate the colorized image.
                    display_well_details (bool): Whether or not the name of the well should be printed on its generated image.
                    plate_name (string): Name of the current plate.
                    scope (string): &#39;plate&#39;,&#39;wells&#39; or &#39;sites&#39; (this will have an impact on the resizing of the well/site images).

            Returns:
                    True (in case of success)
    &#39;&#39;&#39;

    # Define the rescale ratio based on the scope
    if scope == &#39;wells&#39;:
        rescale_ratio = parameters.rescale_ratio_picasso_wells
    elif scope == &#39;plate&#39;:
        rescale_ratio = parameters.rescale_ratio_picasso_plate
    else:
        rescale_ratio = 1

    # Multiplex all well/site channels into 1 well/site 8bit colored image
    wellprogressbar = tqdm(well_list, unit=&#34;wells&#34;, leave=False)
    for current_well in wellprogressbar:
        # For each well, generate the multiplexed images of its 6 sites
        current_well_sites_multiplexed_image_list = []
        for current_site in range(1, 7):

            # Get the image path list for the channels of the site, in the correct order
            current_sites_df = data_df[
                ((data_df[&#34;well&#34;] == current_well) &amp;
                 (data_df[&#34;site&#34;] == current_site))
            ]
            current_sites_df_ordered = current_sites_df.sort_values(
                by=&#34;channel&#34;, ascending=True
            )
            channel_images_path = \
                current_sites_df_ordered[&#34;fullpath&#34;].to_list()

            # Generate the multiplexed image of the current site
            multiplexed_site_image = colorizer(
                img_channels_fullpath=channel_images_path,
                rescale_ratio=rescale_ratio,
                max_multiply_coef=8,
                style=style,
            )

            if scope == &#39;sites&#39;:
                # Return the site image directly
                cv2.imwrite(
                    gen_image_output_folder +
                    f&#34;/{current_well}_s{current_site}.{output_format}&#34;,
                    multiplexed_site_image,
                )

            else:
                # Collect images in memory for site image concatenation
                # into one well image
                current_well_sites_multiplexed_image_list.append(
                    multiplexed_site_image)

        if scope in (&#39;plate&#39;, &#39;wells&#39;):
            # Concatenate the site images into one well image
            sites_row1 = cv2.hconcat(
                current_well_sites_multiplexed_image_list[:3]
            )
            sites_row2 = cv2.hconcat(
                current_well_sites_multiplexed_image_list[3:]
            )
            current_well_image = cv2.vconcat([sites_row1, sites_row2])

            # Add fingerprint on image
            if display_well_details:

                # Compose well label
                text = current_well
                if platemap_path is not None:
                    # If the platemap is provided, extract all required columns
                    pm_well_column = parameters.platemap_columns[&#39;well_column_name&#39;]
                    pm_id_column = parameters.platemap_columns[&#39;id_column_name&#39;]

                    platemap_df = pd.read_csv(platemap_path,
                                              sep=&#39;\t&#39;,
                                              header=0,
                                              usecols=[pm_well_column, pm_id_column])

                    # Select the row of the current well (if there is one)
                    current_platemap_row = platemap_df.loc[platemap_df[pm_well_column]
                                                           == current_well]

                    # If there is indeed a row, add the JCP to the well label
                    if len(current_platemap_row.index) != 0:
                        current_compound = current_platemap_row.iloc[0][pm_id_column]
                        text = current_well + &#34; - &#34; + current_compound

                # Add the label to the well image
                font = cv2.FONT_HERSHEY_SIMPLEX
                cv2.putText(
                    img=current_well_image,
                    text=text,
                    org=(math.ceil(80*rescale_ratio),
                         math.ceil(80*rescale_ratio)),
                    fontFace=font,
                    fontScale=2.2*rescale_ratio,
                    thickness=math.ceil(3*rescale_ratio),
                    color=(192, 192, 192),
                    lineType=cv2.INTER_AREA,
                )

            # Output the well images in the pre-defined temp/output folder
            # depending on the scope
            if scope == &#39;plate&#39;:
                # Add well borders
                image_shape = current_well_image.shape
                cv2.rectangle(
                    current_well_image,
                    (0, 0),
                    (image_shape[1], image_shape[0]),
                    (192, 192, 192),
                    math.ceil(8*rescale_ratio),
                )
                # Return the image
                cv2.imwrite(
                    gen_image_output_folder +
                    f&#34;/wells/well-{current_well}.{output_format}&#34;,
                    current_well_image,
                )
            elif scope == &#39;wells&#39;:
                # Return the image
                cv2.imwrite(
                    gen_image_output_folder +
                    f&#34;/{plate_name}_{current_well}_{style}.{output_format}&#34;,
                    current_well_image,
                )</code></pre>
</details>
</dd>
<dt id="lumos.picasso.get_images_full_path"><code class="name flex">
<span>def <span class="ident">get_images_full_path</span></span>(<span>selected_channels, plate_input_path)</span>
</code></dt>
<dd>
<div class="desc"><p>Finds all the paths to all the channels' images from the input folder</p>
<pre><code>    Parameters:
            selected_channels (string list): A list of all the channels IDs to be loaded.
            plate_input_path (Path): The path to the folder where the input images are stored.

    Returns:
            Path list: A list of all the paths to all images of each channels
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_images_full_path(selected_channels, plate_input_path):
    &#39;&#39;&#39;
    Finds all the paths to all the channels&#39; images from the input folder

            Parameters:
                    selected_channels (string list): A list of all the channels IDs to be loaded.
                    plate_input_path (Path): The path to the folder where the input images are stored.

            Returns:
                    Path list: A list of all the paths to all images of each channels
    &#39;&#39;&#39;

    # Get the files from the plate folder, for the targeted channel
    images_full_path_list = []
    for channel in selected_channels:
        current_channel_images_full_path_list = list(
            Path(plate_input_path).glob(&#34;*&#34; + channel + &#34;.tif&#34;)
        )
        images_full_path_list.extend(current_channel_images_full_path_list)

    # Check that we get expected images for a 384 well image
    try:
        assert len(images_full_path_list) == 2304 * 5
    except AssertionError:
        print(
            &#34;The plate does not have the exact image count: expected &#34; +
            str(2304 * 5) + &#34;, got &#34;
            + str(len(images_full_path_list)),
        )

    return images_full_path_list</code></pre>
</details>
</dd>
<dt id="lumos.picasso.picasso_generate_plate_image"><code class="name flex">
<span>def <span class="ident">picasso_generate_plate_image</span></span>(<span>source_path, plate_name, output_path, temp_folder_path, platemap_path, output_format, style, scope, single_well, display_well_details)</span>
</code></dt>
<dd>
<div class="desc"><p>Generates cell-painted colorized images of individual wells or of a whole plate.</p>
<pre><code>    Parameters:
            source_path (Path): The folder where the input images of the plate are stored.
            plate_name (string): The name of the plate being rendered.
            output_path (Path): The path to the folder where the output images should be stored.
            temp_folder_path (Path): The path to the folder where temporary data can be stored.
            platemap_path (Path): The path to the platemap file of the plate.
            output_format (string): The format/extension of the generated output images.
            style (string): The name of the rendering style.
            scope (string):
                    Either 'wells' or 'plate'. Defines if we should generate individual well images,
                    or concatenate them into a single plate image.
            single_well (string): If not None, name of a unique well to render the image for.
            display_well_details (bool): Whether or not the name of the well should be written on the generated images.

    Returns:
            8 bit cv2 image(s):
                    If the scope is 'wells', then all colorized well images are outputed to the output folder.
                    If the scope is 'plate', then the well images are concatenated into one image of the whole
                    plate before being outputed to the output folder.
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def picasso_generate_plate_image(
    source_path,
    plate_name,
    output_path,
    temp_folder_path,
    platemap_path,
    output_format,
    style,
    scope,
    single_well,
    display_well_details,
):
    &#39;&#39;&#39;
    Generates cell-painted colorized images of individual wells or of a whole plate.

            Parameters:
                    source_path (Path): The folder where the input images of the plate are stored.
                    plate_name (string): The name of the plate being rendered.
                    output_path (Path): The path to the folder where the output images should be stored.
                    temp_folder_path (Path): The path to the folder where temporary data can be stored.
                    platemap_path (Path): The path to the platemap file of the plate.
                    output_format (string): The format/extension of the generated output images.
                    style (string): The name of the rendering style.
                    scope (string):
                            Either &#39;wells&#39; or &#39;plate&#39;. Defines if we should generate individual well images,
                            or concatenate them into a single plate image.
                    single_well (string): If not None, name of a unique well to render the image for.
                    display_well_details (bool): Whether or not the name of the well should be written on the generated images.

            Returns:
                    8 bit cv2 image(s):
                            If the scope is &#39;wells&#39;, then all colorized well images are outputed to the output folder.
                            If the scope is &#39;plate&#39;, then the well images are concatenated into one image of the whole
                            plate before being outputed to the output folder.
    &#39;&#39;&#39;

    created_folder = create_temp_and_output_folders(
        temp_folder_path, output_path, scope, plate_name, style)

    # Get the list of all paths for each channel image
    images_full_path_list = get_images_full_path(
        selected_channels=[&#34;C01&#34;, &#34;C02&#34;, &#34;C03&#34;, &#34;C04&#34;, &#34;C05&#34;],
        plate_input_path=source_path,
    )

    # Build a database of the theorical plate
    # TODO: adapt for less than 5 selected channels?
    data_df = build_robustized_plate_dataframe(images_full_path_list)

    # Get the list of wells to be rendered
    well_list = sorted(data_df[&#34;well&#34;].unique())

    # Handle the single-well request
    if single_well and single_well not in well_list:
        logger.error(&#34;Single-well parameter not a valid well&#34;)
        print(os.linesep, &#34;ERROR:&#34;, single_well,
              &#34;is not a valid well.&#34;, os.linesep)
        sys.exit()
    elif single_well:
        # Override the list of wells to be rendered
        # with the single well
        well_list = [single_well]

    # Generate the Cell-painted well images
    generate_multiplexed_well_images(
        data_df=data_df,
        well_list=well_list,
        gen_image_output_folder=created_folder,
        platemap_path=platemap_path,
        output_format=output_format,
        style=style,
        display_well_details=display_well_details,
        plate_name=plate_name,
        scope=scope,
    )

    if scope in (&#39;sites&#39;, &#39;wells&#39;):
        print(f&#34; -&gt; Saved {scope} images in {output_path}&#34;)
    elif scope == &#39;plate&#39;:
        # Concatenate well images into a plate image
        plate_image = concatenate_well_images(
            well_list, created_folder, output_format)

        # Save the concatenated image in the output folder
        plate_image_path = (
            output_path + f&#34;/{plate_name}-picasso-{style}.{output_format}&#34;
        )
        cv2.imwrite(plate_image_path, plate_image)

        print(&#34; -&gt; Generated image of size:&#34;, plate_image.shape)
        print(&#34; -&gt; Saved as &#34;, plate_image_path)

        # Purge the temp files
        logger.info(&#34;Purge temporary folder&#34;)
        shutil.rmtree(created_folder, ignore_errors=True)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="lumos" href="index.html">lumos</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="lumos.picasso.build_robustized_plate_dataframe" href="#lumos.picasso.build_robustized_plate_dataframe">build_robustized_plate_dataframe</a></code></li>
<li><code><a title="lumos.picasso.colorizer" href="#lumos.picasso.colorizer">colorizer</a></code></li>
<li><code><a title="lumos.picasso.concatenate_well_images" href="#lumos.picasso.concatenate_well_images">concatenate_well_images</a></code></li>
<li><code><a title="lumos.picasso.create_temp_and_output_folders" href="#lumos.picasso.create_temp_and_output_folders">create_temp_and_output_folders</a></code></li>
<li><code><a title="lumos.picasso.generate_multiplexed_well_images" href="#lumos.picasso.generate_multiplexed_well_images">generate_multiplexed_well_images</a></code></li>
<li><code><a title="lumos.picasso.get_images_full_path" href="#lumos.picasso.get_images_full_path">get_images_full_path</a></code></li>
<li><code><a title="lumos.picasso.picasso_generate_plate_image" href="#lumos.picasso.picasso_generate_plate_image">picasso_generate_plate_image</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>