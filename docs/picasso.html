<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>lumos.picasso API documentation</title>
<meta name="description" content="Main functions to generate cell-painted platemaps with Lumos Picasso." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>lumos.picasso</code></h1>
</header>
<section id="section-intro">
<p>Main functions to generate cell-painted platemaps with Lumos Picasso.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#!/usr/bin/env python
# -*- coding: utf-8 -*-

&#39;&#39;&#39;
Main functions to generate cell-painted platemaps with Lumos Picasso.
&#39;&#39;&#39;

import math
import os
from pathlib import Path
import pandas as pd
from shutil import copyfile
import shutil
from . import toolbox
from . import parameters
import cv2
from tqdm import tqdm
from . import logger
import numpy as np
import random


def colorizer(
    img_channels_fullpath,
    rescale_ratio,
    style,
    max_multiply_coef=1,
    display_fingerprint=False,
):
    &#39;&#39;&#39;
    Merges input images from different channels into one RGB image.

            Parameters:
                    img_channels_fullpath (Path list): The list of paths to the channels&#39; images (in proper order [C01,C02,C03,C04,C05]).
                    rescale_ratio (float): The ratio used to rescale the image before generation.
                    style (string): The name of the style being used to generate the colorized image.
                    max_multiply_coef (int): Max multiplication factor in case of random coefficient generation.
                    display_fingerprint (bool): Whether the coefficients used for generation should be printed on the output image.

            Returns:
                    8-bit cv2 image
    &#39;&#39;&#39;

    # load images from path list + resize + convert to 8bit
    np_image_channels_array = []
    for current_image in img_channels_fullpath:
        # load image
        img16 = cv2.imread(str(current_image), -1)
        try:
            assert(not img16.shape == (0, 0))
        except:
            # create blank file
            img16 = np.full(shape=(1000, 1000, 1),
                            fill_value=0, dtype=np.uint16)
            logger.warning(&#34;Missing or corrupted image &#34; + str(current_image))

        # resize image
        img16 = cv2.resize(
            src=img16,
            dsize=None,
            fx=rescale_ratio,
            fy=rescale_ratio,
            interpolation=cv2.INTER_CUBIC,
        )

        # convert image to 8bit
        img8 = (img16 / 256).astype(&#34;uint8&#34;)
        np_image_channels_array.append(img8)

    # Perform merging, according to the style
    if style == &#39;accurate&#39;:
        # initialize RGB channels
        red_channel = np.zeros(np_image_channels_array[0].shape)
        green_channel = np.zeros(np_image_channels_array[0].shape)
        blue_channel = np.zeros(np_image_channels_array[0].shape)

        # # compute the mean of each layer
        # means=[]
        # for idx in range(5):
        #     means.append(np.mean(np_image_channels_array[idx]))

        # # contrast image at the mean of each layer (naive approche)
        # for idx in range(5):
        #     vLambda = np.vectorize(lambda x : ((x**parameters.accurate_style_parameters[&#39;contrast_coeffs&#39;][idx])/means[idx]) if parameters.accurate_style_parameters[&#39;contrast_coeffs&#39;][idx] != 0 else x)
        #     np_image_channels_array[idx] = vLambda(np_image_channels_array[idx])

        # # perform thresholding at the mean of each layer
        # for idx in range(5):
        #     # thresholder = lambda x : x if x &gt; (means[idx] * parameters.accurate_style_parameters[&#39;threshold_coeffs&#39;][idx])  else 0
        #     # vThreshold = np.vectorize(thresholder)
        #     # np_image_channels_array[idx] = vThreshold(np_image_channels_array[idx])

        # get the current style&#39;s contrast coefficients
        contrast_coef = parameters.accurate_style_parameters[&#39;contrast&#39;]
        # add contrast to each layer according to coefficients
        for idx in range(5):
            contrast = contrast_coef[idx]
            f = float(131 * (contrast + 127)) / (127 * (131 - contrast))
            alpha_c = f
            gamma_c = 127*(1-f)
            np_image_channels_array[idx] = cv2.addWeighted(
                np_image_channels_array[idx], alpha_c, np_image_channels_array[idx], 0, gamma_c)

        # get the current style&#39;s intensity coefficients
        intensity_coef = parameters.accurate_style_parameters[&#39;intensity&#39;]
        # multiply the intensity of the channels using input coefs
        np_image_array_adjusted = []
        for idx in range(5):  # TODO: adapt for less than 5 selected channels
            np_image_array_adjusted.append(
                np_image_channels_array[idx] * intensity_coef[idx])
        np_image_channels_array = np_image_array_adjusted

        # combine the images according to their RGB coefficients
        for idx in range(5):
            red_channel = red_channel + \
                (np_image_channels_array[idx] / 255 *
                 parameters.cellplainting_channels_info[idx][3][0])
            green_channel = green_channel + \
                (np_image_channels_array[idx] / 255 *
                 parameters.cellplainting_channels_info[idx][3][1])
            blue_channel = blue_channel + \
                (np_image_channels_array[idx] / 255 *
                 parameters.cellplainting_channels_info[idx][3][2])

        # merge the Blue, Green and Red channels to form the final image
        merged_img = cv2.merge(
            (blue_channel, green_channel, red_channel)
        )

    else:

        # get the current style&#39;s intensity coefficients
        intensity_coef = parameters.fingerprint_style_dict[style][0]

        # get other parameters
        channel_order = parameters.fingerprint_style_dict[style][1]
        target_rgb = parameters.fingerprint_style_dict[style][2]

        # randomly initiate coefficients if they are missing
        if len(intensity_coef) == 0 and len(channel_order) == 0 and len(target_rgb) == 0:
            # parameters for each channel
            intensity_coef = [random.randint(
                1, max_multiply_coef) for x in range(5)]
            channel_order = [0, 1, 2, 3, 4]
            random.shuffle(channel_order)
            target_rgb = [0, 1, 2]
            random.shuffle(target_rgb)

        # multiply the intensity of the channels using input coefs
        np_image_array_adjusted = []
        # TODO: adapt for less than 5 selected channels?
        for index, current_coef_mult in enumerate(intensity_coef):
            np_image_array_adjusted.append(
                np_image_channels_array[index] * current_coef_mult)
        np_image_channels_array = np_image_array_adjusted

        # merge 2 extra channels each on 1 rgb channel
        np_image_channels_array[target_rgb[0]] = (
            np_image_channels_array[target_rgb[0]] +
            np_image_channels_array[channel_order[3]]
        )
        np_image_channels_array[target_rgb[1]] = (
            np_image_channels_array[target_rgb[1]] +
            np_image_channels_array[channel_order[4]]
        )

        merged_img = cv2.merge(
            (
                np_image_channels_array[channel_order[0]],
                np_image_channels_array[channel_order[1]],
                np_image_channels_array[channel_order[2]],
            )
        )

    # add fingerprint id on image
    if display_fingerprint:
        text = str(intensity_coef) + str(channel_order) + str(
            target_rgb) if style != &#39;accurate&#39; else str(parameters.accurate_style_parameters)
        font = cv2.FONT_HERSHEY_SIMPLEX
        cv2.putText(
            merged_img,
            text,
            (math.ceil(10*rescale_ratio), math.ceil(990*rescale_ratio)),
            font,
            0.8*rescale_ratio,
            (192, 192, 192),
            math.ceil(2*rescale_ratio),
            cv2.INTER_AREA,
        )

    return merged_img


def generate_multiplexed_well_images(
    data_df, temp_folder, style, display_well_details, scope
):
    &#39;&#39;&#39;
    Generates a colorized image from all 5 channels of a well, for all wells, and saves it in the temporary directory.

            Parameters:
                    data_df (Pandas DataFrame): Dataframe containing the paths to each channel, of each site, of each well.
                    temp_folder_path (Path): The path to the folder where temporary data can be stored.
                    style (string): The name of the style being used to generate the colorized image.
                    style (string): The name of rendering style.
                    display_well_details (bool): Whether or not the name of the well should be printed on its generated image.
                    scope (string): &#39;plate&#39; or &#39;wells&#39; (this will have an impact on the resizing of the well/site images).

            Returns:
                    True (in case of success)
    &#39;&#39;&#39;

    if scope == &#39;wells&#39;:
        rescale_ratio = parameters.rescale_ratio_picasso_wells
    if scope == &#39;plate&#39;:
        rescale_ratio = parameters.rescale_ratio_picasso_plate

    # get the well list
    well_list = list(set(data_df[&#34;well&#34;]))
    well_list.sort()

    # multiplex all well/site channels into 1 well/site 8bit color image
    wellprogressbar = tqdm(list(well_list), unit=&#34;wells&#34;, leave=False)
    for current_well in wellprogressbar:
        current_well_sites_multiplexed_image_list = []
        for current_site in range(1, 7):

            # get the image path list for the channels of the site, in the correct order
            current_sites_df = data_df[
                ((data_df[&#34;well&#34;] == current_well) &amp;
                 (data_df[&#34;site&#34;] == current_site))
            ]
            current_sites_df_ordered = current_sites_df.sort_values(
                by=&#34;channel&#34;, ascending=True
            )

            channel_images_path = current_sites_df_ordered[&#34;fullpath&#34;].to_list()

            # proceed to the generation using shaker 4 function with a first predefined fingerprint
            multiplexed_image = colorizer(
                img_channels_fullpath=channel_images_path,
                rescale_ratio=rescale_ratio,
                max_multiply_coef=8,
                style=style,
            )

            # collect image in memory
            current_well_sites_multiplexed_image_list.append(multiplexed_image)

        # save well image
        sites_row1 = cv2.hconcat(
            [
                current_well_sites_multiplexed_image_list[0],
                current_well_sites_multiplexed_image_list[1],
                current_well_sites_multiplexed_image_list[2],
            ]
        )
        sites_row2 = cv2.hconcat(
            [
                current_well_sites_multiplexed_image_list[3],
                current_well_sites_multiplexed_image_list[4],
                current_well_sites_multiplexed_image_list[5],
            ]
        )
        all_sites_image = cv2.vconcat([sites_row1, sites_row2])

        # add fingerprint id on image
        if display_well_details:
            text = str(current_well)
            font = cv2.FONT_HERSHEY_SIMPLEX
            cv2.putText(
                img=all_sites_image,
                text=text,
                org=(math.ceil(80*rescale_ratio), math.ceil(80*rescale_ratio)),
                fontFace=font,
                fontScale=2.2*rescale_ratio,
                thickness=math.ceil(3*rescale_ratio),
                color=(192, 192, 192),
                lineType=cv2.INTER_AREA,
            )
        if scope == &#39;plate&#39;:
            # add well marks on borders
            image_shape = all_sites_image.shape
            cv2.rectangle(
                all_sites_image,
                (0, 0),
                (image_shape[1], image_shape[0]),
                (192, 192, 192),
                math.ceil(8*rescale_ratio),
            )

        cv2.imwrite(
            temp_folder + &#34;/wells/well-&#34; + str(current_well) + &#34;.png&#34;,
            all_sites_image,
        )

    return


def concatenate_well_images(well_list, temp_folder_path):
    &#39;&#39;&#39;
    Loads all temporary well images from the temporary directory and concatenates them into one image of the whole plate.

            Parameters:
                    well_list (string list): A list of all the well IDs (e.g. [&#39;A01&#39;, &#39;A02&#39;, &#39;A03&#39;, ...]).
                    temp_folder_path (Path): The path to the folder where temporary data can be stored.

            Returns:
                    8-bit cv2 image: The concatenated image of all the wells
    &#39;&#39;&#39;

    # load all well images and store images in memory into a list
    print(&#34;Load well images in memory..&#34;)
    logger.info(&#34;Load well images in memory..&#34;)

    image_well_data = []
    for current_well in list(well_list):
        well_image = toolbox.load_well_image(
            current_well,
            temp_folder_path + &#34;/wells&#34;,
        )
        image_well_data.append(well_image)

    # concatenate all the well images into horizontal stripes (1 per row)
    logger.info(&#34;Concatenate images into a plate..&#34;)

    image_row_data = []
    for current_plate_row in range(1, 17):

        # concatenate horizontally and vertically
        well_start_id = ((current_plate_row - 1) * 24) + 0
        well_end_id = current_plate_row * 24
        sites_row = cv2.hconcat(image_well_data[well_start_id:well_end_id])
        image_row_data.append(sites_row)

    # concatenate all the stripes into 1 image
    plate_image = cv2.vconcat(image_row_data)
    return plate_image


def get_images_full_path(channel_string_ids, plate_input_path):
    &#39;&#39;&#39;
    Finds all the paths to all the channels&#39; images from the input folder

            Parameters:
                    channel_string_ids (string list): A list of all the channels IDs to be loaded.
                    plate_input_path (Path): The path to the folder where the input images are stored.

            Returns:
                    Path list: A list of all the paths to all images of each channels
    &#39;&#39;&#39;

    # get the files from the plate folder, for the targeted channel
    images_full_path_list = []
    for current_channel in channel_string_ids:
        current_channel_images_full_path_list = list(
            Path(plate_input_path).glob(&#34;*&#34; + current_channel + &#34;.tif&#34;)
        )
        images_full_path_list = images_full_path_list + \
            current_channel_images_full_path_list

    # check that we get expected images for a 384 well image
    try:
        assert len(images_full_path_list) == 2304 * 5
    except AssertionError:
        print(
            &#34;The plate does not have the exact image count: expected &#34; +
            str(2304 * 5) + &#34;, got &#34;
            + str(len(images_full_path_list)),
        )

    return images_full_path_list


def build_robustized_plate_dataframe(images_full_path_list):
    &#39;&#39;&#39;
    Scans the input list of Paths to map it to the expected plate structure.
    Missing images or wells must be taken into account in the final render.

            Parameters:
                    images_full_path_list (Path list): A list of all the paths to all the images to be included in the render.

            Returns:
                    Pandas DataFrame:
                            A database of all the image paths to each channel, of each site, of each well.
                            Its columns are: [&#34;well&#34;, &#34;site&#34;, &#34;channel&#34;, &#34;filename&#34;, &#34;fullpath&#34;].
    &#39;&#39;&#39;

    # get the filenames list
    images_full_path_list.sort()
    images_filename_list = [str(x.name) for x in images_full_path_list]

    # get the well list
    image_well_list = [x.split(&#34;_&#34;)[1].split(&#34;_T&#34;)[0]
                       for x in images_filename_list]

    # get the siteid list (sitesid from 1 to 6)
    image_site_list = [
        x.split(&#34;_T0001F&#34;)[1].split(&#34;L&#34;)[0] for x in images_filename_list
    ]
    image_site_list_int = [int(x) for x in image_site_list]

    # get the channel id list (channel id from 1 to 5)
    image_channel_list = [x.split(&#34;.ti&#34;)[0][-2:] for x in images_filename_list]
    image_channel_list_int = [int(x) for x in image_channel_list]

    # zip all in a data structure
    image_data_zip = zip(
        image_well_list,
        image_site_list_int,
        image_channel_list_int,
        images_filename_list,
        images_full_path_list,
    )

    # convert the zip into dataframe
    data_df = pd.DataFrame(
        list(image_data_zip),
        columns=[&#34;well&#34;, &#34;site&#34;, &#34;channel&#34;, &#34;filename&#34;, &#34;fullpath&#34;],
    )

    # get the theoretical well list for 384 well plate
    well_theoretical_list = [
        l + str(r).zfill(2) for l in &#34;ABCDEFGHIJKLMNOP&#34; for r in range(1, 25)
    ]
    well_channel_theoretical_list = [
        [x, r, c] for x in well_theoretical_list for r in range(1, 7) for c in range(1, 6)
    ]

    # create the theoretical well dataframe
    theoretical_data_df = pd.DataFrame(
        well_channel_theoretical_list, columns=[&#34;well&#34;, &#34;site&#34;, &#34;channel&#34;]
    )

    # join the real wells with the theoric ones
    theoretical_data_df_joined = theoretical_data_df.merge(
        data_df,
        left_on=[&#34;well&#34;, &#34;site&#34;, &#34;channel&#34;],
        right_on=[&#34;well&#34;, &#34;site&#34;, &#34;channel&#34;],
        how=&#34;left&#34;,
    )

    # log if there is a delta between theory and actual plate wells
    delta = set(well_theoretical_list) - set(image_well_list)
    logger.info(&#34;Well Delta &#34; + str(delta))

    return theoretical_data_df_joined


def copy_well_images_to_output_folder(temp_folder, output_path, well_list, plate_name, style):
    &#39;&#39;&#39;
    Copies all temporary well images into the output folder.
    Used for when the scope of the operation is &#39;well&#39; and we want only the well images to be outputed.

            Parameters:
                    temp_folder (Path): The path to the temporary working directory where the well images are currently stored in.
                    output_path (Path): The path to the folder where the images should be copied to.
                    well_list (string list): A list of all the well IDs (e.g. [&#39;A01&#39;, &#39;A02&#39;, &#39;A03&#39;, ...]).
                    plate_name (string): The name of the current plate (used to generate the output files&#39; names).
                    style (string): The name of the style used for rendering (used to generate the output files&#39; names).

            Returns:
                    8 bit cv2 image
    &#39;&#39;&#39;

    print(&#34;Putting well images into output folder..&#34;)

    for current_well in list(well_list):
        copyfile(
            temp_folder + &#34;/wells/well-&#34;+current_well+&#34;.png&#34;,
            output_path+&#39;/&#39;+plate_name+&#34;-&#34;+current_well+&#34;-&#34;+style+&#34;.png&#34;
        )

    return


def picasso_generate_plate_image(
    source_path,
    plate_name,
    output_path,
    temp_folder_path,
    style,
    scope,
    display_well_details,
):
    &#39;&#39;&#39;
    Generates cell-painted colorized images of individual wells or of a whole plate.

            Parameters:
                    source_path (Path): The folder where the input images of the plate are stored.
                    plate_name (string): The name of the plate being rendered.
                    output_path (Path): The path to the folder where the output images should be stored.
                    temp_folder_path (Path): The path to the folder where temporary data can be stored.
                    style (string): The name of the rendering style.
                    scope (string):
                            Either &#39;wells&#39; or &#39;plate&#39;. Defines if we should generate individual well images,
                            or concatenate them into a single plate image.
                    display_well_details (bool): Whether or not the name of the well should be written on the generated images.

            Returns:
                    8 bit cv2 image(s):
                            If the scope is &#39;wells&#39;, then all colorized well images are outputed to the output folder.
                            If the scope is &#39;wells&#39;, then the well images are concatenated into one image of the whole
                            plate before being outputed to the output folder.
    &#39;&#39;&#39;

    # define a temp folder for the run
    temp_folder_path = temp_folder_path + &#34;/tmpgen-&#34; + plate_name + &#34;picasso&#34;

    # remove temp dir if existing
    shutil.rmtree(temp_folder_path, ignore_errors=True)

    # create the temporary directory structure to work on wells
    try:
        os.mkdir(temp_folder_path)
    except FileExistsError:
        pass
    # also create a subfolder to store well images
    try:
        os.mkdir(temp_folder_path + &#34;/wells&#34;)
    except FileExistsError:
        pass

    # read the plate input path
    plate_input_path = Path(source_path)

    # get the list of all paths for each channel image
    images_full_path_list = get_images_full_path(
        # TODO: adapt for less than 5 selected channels?
        channel_string_ids=[&#34;C01&#34;, &#34;C02&#34;, &#34;C03&#34;, &#34;C04&#34;, &#34;C05&#34;],
        plate_input_path=plate_input_path,
    )

    # build a database of the theorical plate
    # TODO: adapt for less than 5 selected channels?
    data_df = build_robustized_plate_dataframe(images_full_path_list)

    # get the well list
    well_list = list(set(data_df[&#34;well&#34;]))
    well_list.sort()

    # generate images inside the temp folder
    generate_multiplexed_well_images(
        data_df=data_df,
        temp_folder=temp_folder_path,
        style=style,
        display_well_details=display_well_details,
        scope=scope,
    )

    if scope == &#39;plate&#39;:
        # concatenate well images into a plate image
        plate_image = concatenate_well_images(well_list, temp_folder_path)

        # save image
        plate_image_path = (
            output_path + &#34;/&#34; + plate_name + &#34;-&#34; +
            &#34;picasso&#34; + &#34;-&#34; + str(style) + &#34;.jpg&#34;
        )
        cv2.imwrite(plate_image_path, plate_image)

        print(&#34; -&gt; Generated image of size:&#34;, plate_image.shape)
        print(&#34; -&gt; Saved as &#34;, plate_image_path)

    if scope == &#39;wells&#39;:
        # copy well files in output folder
        copy_well_images_to_output_folder(
            temp_folder_path, output_path, well_list, plate_name, style)

        print(&#34; -&gt; Saved well images in &#34;, output_path)

    # purge temp files
    logger.info(&#34;Purge temporary folder&#34;)
    shutil.rmtree(temp_folder_path, ignore_errors=True)

    return</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="lumos.picasso.build_robustized_plate_dataframe"><code class="name flex">
<span>def <span class="ident">build_robustized_plate_dataframe</span></span>(<span>images_full_path_list)</span>
</code></dt>
<dd>
<div class="desc"><p>Scans the input list of Paths to map it to the expected plate structure.
Missing images or wells must be taken into account in the final render.</p>
<pre><code>    Parameters:
            images_full_path_list (Path list): A list of all the paths to all the images to be included in the render.

    Returns:
            Pandas DataFrame:
                    A database of all the image paths to each channel, of each site, of each well.
                    Its columns are: ["well", "site", "channel", "filename", "fullpath"].
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build_robustized_plate_dataframe(images_full_path_list):
    &#39;&#39;&#39;
    Scans the input list of Paths to map it to the expected plate structure.
    Missing images or wells must be taken into account in the final render.

            Parameters:
                    images_full_path_list (Path list): A list of all the paths to all the images to be included in the render.

            Returns:
                    Pandas DataFrame:
                            A database of all the image paths to each channel, of each site, of each well.
                            Its columns are: [&#34;well&#34;, &#34;site&#34;, &#34;channel&#34;, &#34;filename&#34;, &#34;fullpath&#34;].
    &#39;&#39;&#39;

    # get the filenames list
    images_full_path_list.sort()
    images_filename_list = [str(x.name) for x in images_full_path_list]

    # get the well list
    image_well_list = [x.split(&#34;_&#34;)[1].split(&#34;_T&#34;)[0]
                       for x in images_filename_list]

    # get the siteid list (sitesid from 1 to 6)
    image_site_list = [
        x.split(&#34;_T0001F&#34;)[1].split(&#34;L&#34;)[0] for x in images_filename_list
    ]
    image_site_list_int = [int(x) for x in image_site_list]

    # get the channel id list (channel id from 1 to 5)
    image_channel_list = [x.split(&#34;.ti&#34;)[0][-2:] for x in images_filename_list]
    image_channel_list_int = [int(x) for x in image_channel_list]

    # zip all in a data structure
    image_data_zip = zip(
        image_well_list,
        image_site_list_int,
        image_channel_list_int,
        images_filename_list,
        images_full_path_list,
    )

    # convert the zip into dataframe
    data_df = pd.DataFrame(
        list(image_data_zip),
        columns=[&#34;well&#34;, &#34;site&#34;, &#34;channel&#34;, &#34;filename&#34;, &#34;fullpath&#34;],
    )

    # get the theoretical well list for 384 well plate
    well_theoretical_list = [
        l + str(r).zfill(2) for l in &#34;ABCDEFGHIJKLMNOP&#34; for r in range(1, 25)
    ]
    well_channel_theoretical_list = [
        [x, r, c] for x in well_theoretical_list for r in range(1, 7) for c in range(1, 6)
    ]

    # create the theoretical well dataframe
    theoretical_data_df = pd.DataFrame(
        well_channel_theoretical_list, columns=[&#34;well&#34;, &#34;site&#34;, &#34;channel&#34;]
    )

    # join the real wells with the theoric ones
    theoretical_data_df_joined = theoretical_data_df.merge(
        data_df,
        left_on=[&#34;well&#34;, &#34;site&#34;, &#34;channel&#34;],
        right_on=[&#34;well&#34;, &#34;site&#34;, &#34;channel&#34;],
        how=&#34;left&#34;,
    )

    # log if there is a delta between theory and actual plate wells
    delta = set(well_theoretical_list) - set(image_well_list)
    logger.info(&#34;Well Delta &#34; + str(delta))

    return theoretical_data_df_joined</code></pre>
</details>
</dd>
<dt id="lumos.picasso.colorizer"><code class="name flex">
<span>def <span class="ident">colorizer</span></span>(<span>img_channels_fullpath, rescale_ratio, style, max_multiply_coef=1, display_fingerprint=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Merges input images from different channels into one RGB image.</p>
<pre><code>    Parameters:
            img_channels_fullpath (Path list): The list of paths to the channels' images (in proper order [C01,C02,C03,C04,C05]).
            rescale_ratio (float): The ratio used to rescale the image before generation.
            style (string): The name of the style being used to generate the colorized image.
            max_multiply_coef (int): Max multiplication factor in case of random coefficient generation.
            display_fingerprint (bool): Whether the coefficients used for generation should be printed on the output image.

    Returns:
            8-bit cv2 image
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def colorizer(
    img_channels_fullpath,
    rescale_ratio,
    style,
    max_multiply_coef=1,
    display_fingerprint=False,
):
    &#39;&#39;&#39;
    Merges input images from different channels into one RGB image.

            Parameters:
                    img_channels_fullpath (Path list): The list of paths to the channels&#39; images (in proper order [C01,C02,C03,C04,C05]).
                    rescale_ratio (float): The ratio used to rescale the image before generation.
                    style (string): The name of the style being used to generate the colorized image.
                    max_multiply_coef (int): Max multiplication factor in case of random coefficient generation.
                    display_fingerprint (bool): Whether the coefficients used for generation should be printed on the output image.

            Returns:
                    8-bit cv2 image
    &#39;&#39;&#39;

    # load images from path list + resize + convert to 8bit
    np_image_channels_array = []
    for current_image in img_channels_fullpath:
        # load image
        img16 = cv2.imread(str(current_image), -1)
        try:
            assert(not img16.shape == (0, 0))
        except:
            # create blank file
            img16 = np.full(shape=(1000, 1000, 1),
                            fill_value=0, dtype=np.uint16)
            logger.warning(&#34;Missing or corrupted image &#34; + str(current_image))

        # resize image
        img16 = cv2.resize(
            src=img16,
            dsize=None,
            fx=rescale_ratio,
            fy=rescale_ratio,
            interpolation=cv2.INTER_CUBIC,
        )

        # convert image to 8bit
        img8 = (img16 / 256).astype(&#34;uint8&#34;)
        np_image_channels_array.append(img8)

    # Perform merging, according to the style
    if style == &#39;accurate&#39;:
        # initialize RGB channels
        red_channel = np.zeros(np_image_channels_array[0].shape)
        green_channel = np.zeros(np_image_channels_array[0].shape)
        blue_channel = np.zeros(np_image_channels_array[0].shape)

        # # compute the mean of each layer
        # means=[]
        # for idx in range(5):
        #     means.append(np.mean(np_image_channels_array[idx]))

        # # contrast image at the mean of each layer (naive approche)
        # for idx in range(5):
        #     vLambda = np.vectorize(lambda x : ((x**parameters.accurate_style_parameters[&#39;contrast_coeffs&#39;][idx])/means[idx]) if parameters.accurate_style_parameters[&#39;contrast_coeffs&#39;][idx] != 0 else x)
        #     np_image_channels_array[idx] = vLambda(np_image_channels_array[idx])

        # # perform thresholding at the mean of each layer
        # for idx in range(5):
        #     # thresholder = lambda x : x if x &gt; (means[idx] * parameters.accurate_style_parameters[&#39;threshold_coeffs&#39;][idx])  else 0
        #     # vThreshold = np.vectorize(thresholder)
        #     # np_image_channels_array[idx] = vThreshold(np_image_channels_array[idx])

        # get the current style&#39;s contrast coefficients
        contrast_coef = parameters.accurate_style_parameters[&#39;contrast&#39;]
        # add contrast to each layer according to coefficients
        for idx in range(5):
            contrast = contrast_coef[idx]
            f = float(131 * (contrast + 127)) / (127 * (131 - contrast))
            alpha_c = f
            gamma_c = 127*(1-f)
            np_image_channels_array[idx] = cv2.addWeighted(
                np_image_channels_array[idx], alpha_c, np_image_channels_array[idx], 0, gamma_c)

        # get the current style&#39;s intensity coefficients
        intensity_coef = parameters.accurate_style_parameters[&#39;intensity&#39;]
        # multiply the intensity of the channels using input coefs
        np_image_array_adjusted = []
        for idx in range(5):  # TODO: adapt for less than 5 selected channels
            np_image_array_adjusted.append(
                np_image_channels_array[idx] * intensity_coef[idx])
        np_image_channels_array = np_image_array_adjusted

        # combine the images according to their RGB coefficients
        for idx in range(5):
            red_channel = red_channel + \
                (np_image_channels_array[idx] / 255 *
                 parameters.cellplainting_channels_info[idx][3][0])
            green_channel = green_channel + \
                (np_image_channels_array[idx] / 255 *
                 parameters.cellplainting_channels_info[idx][3][1])
            blue_channel = blue_channel + \
                (np_image_channels_array[idx] / 255 *
                 parameters.cellplainting_channels_info[idx][3][2])

        # merge the Blue, Green and Red channels to form the final image
        merged_img = cv2.merge(
            (blue_channel, green_channel, red_channel)
        )

    else:

        # get the current style&#39;s intensity coefficients
        intensity_coef = parameters.fingerprint_style_dict[style][0]

        # get other parameters
        channel_order = parameters.fingerprint_style_dict[style][1]
        target_rgb = parameters.fingerprint_style_dict[style][2]

        # randomly initiate coefficients if they are missing
        if len(intensity_coef) == 0 and len(channel_order) == 0 and len(target_rgb) == 0:
            # parameters for each channel
            intensity_coef = [random.randint(
                1, max_multiply_coef) for x in range(5)]
            channel_order = [0, 1, 2, 3, 4]
            random.shuffle(channel_order)
            target_rgb = [0, 1, 2]
            random.shuffle(target_rgb)

        # multiply the intensity of the channels using input coefs
        np_image_array_adjusted = []
        # TODO: adapt for less than 5 selected channels?
        for index, current_coef_mult in enumerate(intensity_coef):
            np_image_array_adjusted.append(
                np_image_channels_array[index] * current_coef_mult)
        np_image_channels_array = np_image_array_adjusted

        # merge 2 extra channels each on 1 rgb channel
        np_image_channels_array[target_rgb[0]] = (
            np_image_channels_array[target_rgb[0]] +
            np_image_channels_array[channel_order[3]]
        )
        np_image_channels_array[target_rgb[1]] = (
            np_image_channels_array[target_rgb[1]] +
            np_image_channels_array[channel_order[4]]
        )

        merged_img = cv2.merge(
            (
                np_image_channels_array[channel_order[0]],
                np_image_channels_array[channel_order[1]],
                np_image_channels_array[channel_order[2]],
            )
        )

    # add fingerprint id on image
    if display_fingerprint:
        text = str(intensity_coef) + str(channel_order) + str(
            target_rgb) if style != &#39;accurate&#39; else str(parameters.accurate_style_parameters)
        font = cv2.FONT_HERSHEY_SIMPLEX
        cv2.putText(
            merged_img,
            text,
            (math.ceil(10*rescale_ratio), math.ceil(990*rescale_ratio)),
            font,
            0.8*rescale_ratio,
            (192, 192, 192),
            math.ceil(2*rescale_ratio),
            cv2.INTER_AREA,
        )

    return merged_img</code></pre>
</details>
</dd>
<dt id="lumos.picasso.concatenate_well_images"><code class="name flex">
<span>def <span class="ident">concatenate_well_images</span></span>(<span>well_list, temp_folder_path)</span>
</code></dt>
<dd>
<div class="desc"><p>Loads all temporary well images from the temporary directory and concatenates them into one image of the whole plate.</p>
<pre><code>    Parameters:
            well_list (string list): A list of all the well IDs (e.g. ['A01', 'A02', 'A03', ...]).
            temp_folder_path (Path): The path to the folder where temporary data can be stored.

    Returns:
            8-bit cv2 image: The concatenated image of all the wells
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def concatenate_well_images(well_list, temp_folder_path):
    &#39;&#39;&#39;
    Loads all temporary well images from the temporary directory and concatenates them into one image of the whole plate.

            Parameters:
                    well_list (string list): A list of all the well IDs (e.g. [&#39;A01&#39;, &#39;A02&#39;, &#39;A03&#39;, ...]).
                    temp_folder_path (Path): The path to the folder where temporary data can be stored.

            Returns:
                    8-bit cv2 image: The concatenated image of all the wells
    &#39;&#39;&#39;

    # load all well images and store images in memory into a list
    print(&#34;Load well images in memory..&#34;)
    logger.info(&#34;Load well images in memory..&#34;)

    image_well_data = []
    for current_well in list(well_list):
        well_image = toolbox.load_well_image(
            current_well,
            temp_folder_path + &#34;/wells&#34;,
        )
        image_well_data.append(well_image)

    # concatenate all the well images into horizontal stripes (1 per row)
    logger.info(&#34;Concatenate images into a plate..&#34;)

    image_row_data = []
    for current_plate_row in range(1, 17):

        # concatenate horizontally and vertically
        well_start_id = ((current_plate_row - 1) * 24) + 0
        well_end_id = current_plate_row * 24
        sites_row = cv2.hconcat(image_well_data[well_start_id:well_end_id])
        image_row_data.append(sites_row)

    # concatenate all the stripes into 1 image
    plate_image = cv2.vconcat(image_row_data)
    return plate_image</code></pre>
</details>
</dd>
<dt id="lumos.picasso.copy_well_images_to_output_folder"><code class="name flex">
<span>def <span class="ident">copy_well_images_to_output_folder</span></span>(<span>temp_folder, output_path, well_list, plate_name, style)</span>
</code></dt>
<dd>
<div class="desc"><p>Copies all temporary well images into the output folder.
Used for when the scope of the operation is 'well' and we want only the well images to be outputed.</p>
<pre><code>    Parameters:
            temp_folder (Path): The path to the temporary working directory where the well images are currently stored in.
            output_path (Path): The path to the folder where the images should be copied to.
            well_list (string list): A list of all the well IDs (e.g. ['A01', 'A02', 'A03', ...]).
            plate_name (string): The name of the current plate (used to generate the output files' names).
            style (string): The name of the style used for rendering (used to generate the output files' names).

    Returns:
            8 bit cv2 image
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def copy_well_images_to_output_folder(temp_folder, output_path, well_list, plate_name, style):
    &#39;&#39;&#39;
    Copies all temporary well images into the output folder.
    Used for when the scope of the operation is &#39;well&#39; and we want only the well images to be outputed.

            Parameters:
                    temp_folder (Path): The path to the temporary working directory where the well images are currently stored in.
                    output_path (Path): The path to the folder where the images should be copied to.
                    well_list (string list): A list of all the well IDs (e.g. [&#39;A01&#39;, &#39;A02&#39;, &#39;A03&#39;, ...]).
                    plate_name (string): The name of the current plate (used to generate the output files&#39; names).
                    style (string): The name of the style used for rendering (used to generate the output files&#39; names).

            Returns:
                    8 bit cv2 image
    &#39;&#39;&#39;

    print(&#34;Putting well images into output folder..&#34;)

    for current_well in list(well_list):
        copyfile(
            temp_folder + &#34;/wells/well-&#34;+current_well+&#34;.png&#34;,
            output_path+&#39;/&#39;+plate_name+&#34;-&#34;+current_well+&#34;-&#34;+style+&#34;.png&#34;
        )

    return</code></pre>
</details>
</dd>
<dt id="lumos.picasso.generate_multiplexed_well_images"><code class="name flex">
<span>def <span class="ident">generate_multiplexed_well_images</span></span>(<span>data_df, temp_folder, style, display_well_details, scope)</span>
</code></dt>
<dd>
<div class="desc"><p>Generates a colorized image from all 5 channels of a well, for all wells, and saves it in the temporary directory.</p>
<pre><code>    Parameters:
            data_df (Pandas DataFrame): Dataframe containing the paths to each channel, of each site, of each well.
            temp_folder_path (Path): The path to the folder where temporary data can be stored.
            style (string): The name of the style being used to generate the colorized image.
            style (string): The name of rendering style.
            display_well_details (bool): Whether or not the name of the well should be printed on its generated image.
            scope (string): 'plate' or 'wells' (this will have an impact on the resizing of the well/site images).

    Returns:
            True (in case of success)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_multiplexed_well_images(
    data_df, temp_folder, style, display_well_details, scope
):
    &#39;&#39;&#39;
    Generates a colorized image from all 5 channels of a well, for all wells, and saves it in the temporary directory.

            Parameters:
                    data_df (Pandas DataFrame): Dataframe containing the paths to each channel, of each site, of each well.
                    temp_folder_path (Path): The path to the folder where temporary data can be stored.
                    style (string): The name of the style being used to generate the colorized image.
                    style (string): The name of rendering style.
                    display_well_details (bool): Whether or not the name of the well should be printed on its generated image.
                    scope (string): &#39;plate&#39; or &#39;wells&#39; (this will have an impact on the resizing of the well/site images).

            Returns:
                    True (in case of success)
    &#39;&#39;&#39;

    if scope == &#39;wells&#39;:
        rescale_ratio = parameters.rescale_ratio_picasso_wells
    if scope == &#39;plate&#39;:
        rescale_ratio = parameters.rescale_ratio_picasso_plate

    # get the well list
    well_list = list(set(data_df[&#34;well&#34;]))
    well_list.sort()

    # multiplex all well/site channels into 1 well/site 8bit color image
    wellprogressbar = tqdm(list(well_list), unit=&#34;wells&#34;, leave=False)
    for current_well in wellprogressbar:
        current_well_sites_multiplexed_image_list = []
        for current_site in range(1, 7):

            # get the image path list for the channels of the site, in the correct order
            current_sites_df = data_df[
                ((data_df[&#34;well&#34;] == current_well) &amp;
                 (data_df[&#34;site&#34;] == current_site))
            ]
            current_sites_df_ordered = current_sites_df.sort_values(
                by=&#34;channel&#34;, ascending=True
            )

            channel_images_path = current_sites_df_ordered[&#34;fullpath&#34;].to_list()

            # proceed to the generation using shaker 4 function with a first predefined fingerprint
            multiplexed_image = colorizer(
                img_channels_fullpath=channel_images_path,
                rescale_ratio=rescale_ratio,
                max_multiply_coef=8,
                style=style,
            )

            # collect image in memory
            current_well_sites_multiplexed_image_list.append(multiplexed_image)

        # save well image
        sites_row1 = cv2.hconcat(
            [
                current_well_sites_multiplexed_image_list[0],
                current_well_sites_multiplexed_image_list[1],
                current_well_sites_multiplexed_image_list[2],
            ]
        )
        sites_row2 = cv2.hconcat(
            [
                current_well_sites_multiplexed_image_list[3],
                current_well_sites_multiplexed_image_list[4],
                current_well_sites_multiplexed_image_list[5],
            ]
        )
        all_sites_image = cv2.vconcat([sites_row1, sites_row2])

        # add fingerprint id on image
        if display_well_details:
            text = str(current_well)
            font = cv2.FONT_HERSHEY_SIMPLEX
            cv2.putText(
                img=all_sites_image,
                text=text,
                org=(math.ceil(80*rescale_ratio), math.ceil(80*rescale_ratio)),
                fontFace=font,
                fontScale=2.2*rescale_ratio,
                thickness=math.ceil(3*rescale_ratio),
                color=(192, 192, 192),
                lineType=cv2.INTER_AREA,
            )
        if scope == &#39;plate&#39;:
            # add well marks on borders
            image_shape = all_sites_image.shape
            cv2.rectangle(
                all_sites_image,
                (0, 0),
                (image_shape[1], image_shape[0]),
                (192, 192, 192),
                math.ceil(8*rescale_ratio),
            )

        cv2.imwrite(
            temp_folder + &#34;/wells/well-&#34; + str(current_well) + &#34;.png&#34;,
            all_sites_image,
        )

    return</code></pre>
</details>
</dd>
<dt id="lumos.picasso.get_images_full_path"><code class="name flex">
<span>def <span class="ident">get_images_full_path</span></span>(<span>channel_string_ids, plate_input_path)</span>
</code></dt>
<dd>
<div class="desc"><p>Finds all the paths to all the channels' images from the input folder</p>
<pre><code>    Parameters:
            channel_string_ids (string list): A list of all the channels IDs to be loaded.
            plate_input_path (Path): The path to the folder where the input images are stored.

    Returns:
            Path list: A list of all the paths to all images of each channels
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_images_full_path(channel_string_ids, plate_input_path):
    &#39;&#39;&#39;
    Finds all the paths to all the channels&#39; images from the input folder

            Parameters:
                    channel_string_ids (string list): A list of all the channels IDs to be loaded.
                    plate_input_path (Path): The path to the folder where the input images are stored.

            Returns:
                    Path list: A list of all the paths to all images of each channels
    &#39;&#39;&#39;

    # get the files from the plate folder, for the targeted channel
    images_full_path_list = []
    for current_channel in channel_string_ids:
        current_channel_images_full_path_list = list(
            Path(plate_input_path).glob(&#34;*&#34; + current_channel + &#34;.tif&#34;)
        )
        images_full_path_list = images_full_path_list + \
            current_channel_images_full_path_list

    # check that we get expected images for a 384 well image
    try:
        assert len(images_full_path_list) == 2304 * 5
    except AssertionError:
        print(
            &#34;The plate does not have the exact image count: expected &#34; +
            str(2304 * 5) + &#34;, got &#34;
            + str(len(images_full_path_list)),
        )

    return images_full_path_list</code></pre>
</details>
</dd>
<dt id="lumos.picasso.picasso_generate_plate_image"><code class="name flex">
<span>def <span class="ident">picasso_generate_plate_image</span></span>(<span>source_path, plate_name, output_path, temp_folder_path, style, scope, display_well_details)</span>
</code></dt>
<dd>
<div class="desc"><p>Generates cell-painted colorized images of individual wells or of a whole plate.</p>
<pre><code>    Parameters:
            source_path (Path): The folder where the input images of the plate are stored.
            plate_name (string): The name of the plate being rendered.
            output_path (Path): The path to the folder where the output images should be stored.
            temp_folder_path (Path): The path to the folder where temporary data can be stored.
            style (string): The name of the rendering style.
            scope (string):
                    Either 'wells' or 'plate'. Defines if we should generate individual well images,
                    or concatenate them into a single plate image.
            display_well_details (bool): Whether or not the name of the well should be written on the generated images.

    Returns:
            8 bit cv2 image(s):
                    If the scope is 'wells', then all colorized well images are outputed to the output folder.
                    If the scope is 'wells', then the well images are concatenated into one image of the whole
                    plate before being outputed to the output folder.
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def picasso_generate_plate_image(
    source_path,
    plate_name,
    output_path,
    temp_folder_path,
    style,
    scope,
    display_well_details,
):
    &#39;&#39;&#39;
    Generates cell-painted colorized images of individual wells or of a whole plate.

            Parameters:
                    source_path (Path): The folder where the input images of the plate are stored.
                    plate_name (string): The name of the plate being rendered.
                    output_path (Path): The path to the folder where the output images should be stored.
                    temp_folder_path (Path): The path to the folder where temporary data can be stored.
                    style (string): The name of the rendering style.
                    scope (string):
                            Either &#39;wells&#39; or &#39;plate&#39;. Defines if we should generate individual well images,
                            or concatenate them into a single plate image.
                    display_well_details (bool): Whether or not the name of the well should be written on the generated images.

            Returns:
                    8 bit cv2 image(s):
                            If the scope is &#39;wells&#39;, then all colorized well images are outputed to the output folder.
                            If the scope is &#39;wells&#39;, then the well images are concatenated into one image of the whole
                            plate before being outputed to the output folder.
    &#39;&#39;&#39;

    # define a temp folder for the run
    temp_folder_path = temp_folder_path + &#34;/tmpgen-&#34; + plate_name + &#34;picasso&#34;

    # remove temp dir if existing
    shutil.rmtree(temp_folder_path, ignore_errors=True)

    # create the temporary directory structure to work on wells
    try:
        os.mkdir(temp_folder_path)
    except FileExistsError:
        pass
    # also create a subfolder to store well images
    try:
        os.mkdir(temp_folder_path + &#34;/wells&#34;)
    except FileExistsError:
        pass

    # read the plate input path
    plate_input_path = Path(source_path)

    # get the list of all paths for each channel image
    images_full_path_list = get_images_full_path(
        # TODO: adapt for less than 5 selected channels?
        channel_string_ids=[&#34;C01&#34;, &#34;C02&#34;, &#34;C03&#34;, &#34;C04&#34;, &#34;C05&#34;],
        plate_input_path=plate_input_path,
    )

    # build a database of the theorical plate
    # TODO: adapt for less than 5 selected channels?
    data_df = build_robustized_plate_dataframe(images_full_path_list)

    # get the well list
    well_list = list(set(data_df[&#34;well&#34;]))
    well_list.sort()

    # generate images inside the temp folder
    generate_multiplexed_well_images(
        data_df=data_df,
        temp_folder=temp_folder_path,
        style=style,
        display_well_details=display_well_details,
        scope=scope,
    )

    if scope == &#39;plate&#39;:
        # concatenate well images into a plate image
        plate_image = concatenate_well_images(well_list, temp_folder_path)

        # save image
        plate_image_path = (
            output_path + &#34;/&#34; + plate_name + &#34;-&#34; +
            &#34;picasso&#34; + &#34;-&#34; + str(style) + &#34;.jpg&#34;
        )
        cv2.imwrite(plate_image_path, plate_image)

        print(&#34; -&gt; Generated image of size:&#34;, plate_image.shape)
        print(&#34; -&gt; Saved as &#34;, plate_image_path)

    if scope == &#39;wells&#39;:
        # copy well files in output folder
        copy_well_images_to_output_folder(
            temp_folder_path, output_path, well_list, plate_name, style)

        print(&#34; -&gt; Saved well images in &#34;, output_path)

    # purge temp files
    logger.info(&#34;Purge temporary folder&#34;)
    shutil.rmtree(temp_folder_path, ignore_errors=True)

    return</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="lumos" href="index.html">lumos</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="lumos.picasso.build_robustized_plate_dataframe" href="#lumos.picasso.build_robustized_plate_dataframe">build_robustized_plate_dataframe</a></code></li>
<li><code><a title="lumos.picasso.colorizer" href="#lumos.picasso.colorizer">colorizer</a></code></li>
<li><code><a title="lumos.picasso.concatenate_well_images" href="#lumos.picasso.concatenate_well_images">concatenate_well_images</a></code></li>
<li><code><a title="lumos.picasso.copy_well_images_to_output_folder" href="#lumos.picasso.copy_well_images_to_output_folder">copy_well_images_to_output_folder</a></code></li>
<li><code><a title="lumos.picasso.generate_multiplexed_well_images" href="#lumos.picasso.generate_multiplexed_well_images">generate_multiplexed_well_images</a></code></li>
<li><code><a title="lumos.picasso.get_images_full_path" href="#lumos.picasso.get_images_full_path">get_images_full_path</a></code></li>
<li><code><a title="lumos.picasso.picasso_generate_plate_image" href="#lumos.picasso.picasso_generate_plate_image">picasso_generate_plate_image</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>